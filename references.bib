@inproceedings{rajpurkar2018know,
    title="Know What You Don{'}t Know: Unanswerable Questions for {SQ}u{AD}",
    author="Rajpurkar, Pranav and Jia, Robin and Liang, Percy",
    booktitle="Association for Computational Linguistics (ACL)",
    year="2018",
}
@misc{compas_dataset,
    title="COMPAS dataset",
    url="https://www.kaggle.com/datasets/danofer/compass",
    author="ProPublica",
    year="2016",
    note="Accessed: 2025-07-01",}

@misc{acs_dataset,
    title="American Community Survey (ACS) dataset",
    url="https://www.census.gov/programs-surveys/acs",
    author="U.S. Census Bureau",
    year="2018",
    note="Accessed: 2025-07-01",
}

@article{cifar10_dataset,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada},
  doi={10.24432/C5889J}
}

@INPROCEEDINGS{imagenet_dataset,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  keywords={Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
  doi={10.1109/CVPR.2009.5206848}}

@inproceedings{examples_cf_applications,
author = {Mothilal, Ramaravind K. and Sharma, Amit and Tan, Chenhao},
title = {Explaining machine learning classifiers through diverse counterfactual explanations},
year = {2020},
isbn = {9781450369367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3351095.3372850},
doi = {10.1145/3351095.3372850},
abstract = {Post-hoc explanations of machine learning models are crucial for people to understand and act on algorithmic predictions. An intriguing class of explanations is through counterfactuals, hypothetical examples that show people how to obtain a different prediction. We posit that effective counterfactual explanations should satisfy two properties: feasibility of the counterfactual actions given user context and constraints, and diversity among the counterfactuals presented. To this end, we propose a framework for generating and evaluating a diverse set of counterfactual explanations based on determinantal point processes. To evaluate the actionability of counterfactuals, we provide metrics that enable comparison of counterfactual-based methods to other local explanation methods. We further address necessary tradeoffs and point to causal implications in optimizing for counterfactuals. Our experiments on four real-world datasets show that our framework can generate a set of counterfactuals that are diverse and well approximate local decision boundaries, outperforming prior approaches to generating diverse counterfactuals. We provide an implementation of the framework at https://github.com/microsoft/DiCE.},
booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
pages = {607–617},
numpages = {11},
location = {Barcelona, Spain},
series = {FAT* '20}
}
@misc{papernot2016transferabilitymachinelearningphenomena,
      title={Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples}, 
      author={Nicolas Papernot and Patrick McDaniel and Ian Goodfellow},
      year={2016},
      eprint={1605.07277},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/1605.07277}, 
}

@inproceedings{dice_cf, 
  series={FAT* ’20},
   title={Explaining machine learning classifiers through diverse counterfactual explanations},
   url={http://dx.doi.org/10.1145/3351095.3372850},
   DOI={10.1145/3351095.3372850},
   booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
   publisher={ACM},
   author={Mothilal, Ramaravind K. and Sharma, Amit and Tan, Chenhao},
   year={2020},
   month=jan, pages={607–617},
   collection={FAT* ’20} 
}

@ARTICLE{mnist_dataset,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
  doi={10.1109/5.726791}}

  @misc{fashion_mnist,
      title={Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms}, 
      author={Han Xiao and Kashif Rasul and Roland Vollgraf},
      year={2017},
      eprint={1708.07747},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1708.07747}, 
}

@inbook{spearman_rank_correlation,
author = {Zar, Jerrold},
year = {2005},
month = {07},
pages = {},
title = {Spearman Rank Correlation},
volume = {5},
isbn = {9780470011812},
journal = {Encycl Biostat},
doi = {10.1002/0470011815.b2a15150}
}

@misc{mao2023crossentropylossfunctionstheoretical,
      title={Cross-Entropy Loss Functions: Theoretical Analysis and Applications}, 
      author={Anqi Mao and Mehryar Mohri and Yutao Zhong},
      year={2023},
      eprint={2304.07288},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2304.07288}, 
}